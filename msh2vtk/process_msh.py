#!/usr/bin/env python3
"""
Standalone MSH processor for Fossils output
This script processes MSH files generated by Fossils and converts them to CSV/VTK
It runs as a separate process to avoid gmsh initialization conflicts
"""

import sys
import os
import argparse
import numpy as np
import pandas as pd

try:
    import gmsh
    import pyvista as pv
    MSH_PROCESSING_AVAILABLE = True
except ImportError as e:
    print(f"‚ùå MSH processing libraries not available: {e}")
    MSH_PROCESSING_AVAILABLE = False
    sys.exit(1)

def find_msh_files(python_file):
    """Find MSH files generated by Fossils with enhanced search pattern"""
    base_name = os.path.splitext(os.path.basename(python_file))[0]
    parent_dir = os.path.dirname(python_file)
    
    # Get the directory where this script is running from
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # List of possible locations to search for MSH files
    possible_locations = []
    
    # 1. Same folder as python file (original expected location)
    possible_locations.append(os.path.splitext(python_file)[0])
    
    # 2. Workspace folder in the same directory as python file
    possible_locations.append(os.path.join(parent_dir, "workspace", base_name))
    
    # 3. Workspace folder in the script directory
    possible_locations.append(os.path.join(script_dir, "workspace", base_name))
    
    # 4. Search for folders that contain part of the python file name in workspace directories
    workspace_dirs = [
        os.path.join(parent_dir, "workspace"),
        os.path.join(script_dir, "workspace")
    ]
    
    for workspace_dir in workspace_dirs:
        if os.path.exists(workspace_dir):
            try:
                for folder_name in os.listdir(workspace_dir):
                    folder_path = os.path.join(workspace_dir, folder_name)
                    if os.path.isdir(folder_path):
                        # Check if the folder name contains the base name of our python file
                        if (base_name.lower() in folder_name.lower() or 
                            folder_name.lower() in base_name.lower() or
                            any(word in folder_name.lower() for word in base_name.lower().split('_') if len(word) > 3)):
                            possible_locations.append(folder_path)
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Error scanning workspace directory {workspace_dir}: {e}")
    
    # Remove duplicates while preserving order
    seen = set()
    unique_locations = []
    for location in possible_locations:
        if location not in seen:
            seen.add(location)
            unique_locations.append(location)
    
    print(f"üîç Searching for MSH files for: {base_name}")
    print(f"   Checking {len(unique_locations)} possible locations...")
    
    # Check each possible location
    for i, folder_path in enumerate(unique_locations, 1):
        print(f"   {i}. Checking: {folder_path}")
        
        if not os.path.exists(folder_path):
            print(f"      ‚ùå Directory does not exist")
            continue
            
        mesh_file = os.path.join(folder_path, 'mesh.msh')
        stress_tensor_file = os.path.join(folder_path, 'smooth_stress_tensor.msh')
        force_vector_file = os.path.join(folder_path, 'force_vector.msh')

        # Check if all required files exist
        files_exist = [
            os.path.exists(mesh_file),
            os.path.exists(stress_tensor_file),
            os.path.exists(force_vector_file)
        ]
        
        print(f"      üìÑ mesh.msh: {'‚úÖ' if files_exist[0] else '‚ùå'}")
        print(f"      üìÑ smooth_stress_tensor.msh: {'‚úÖ' if files_exist[1] else '‚ùå'}")
        print(f"      üìÑ force_vector.msh: {'‚úÖ' if files_exist[2] else '‚ùå'}")

        if all(files_exist):
            print(f"   ‚úÖ Found all MSH files in: {folder_path}")
            return mesh_file, stress_tensor_file, force_vector_file
    
    print(f"‚ùå MSH files not found in any of the {len(unique_locations)} locations checked")
    return None, None, None

def process_msh_files(selected_file, export_von_mises=True, export_smooth_stress=True, export_vtk=True):
    """Process Fossils output MSH files and convert them to CSV/VTK"""
    try:
        mesh_file, stress_tensor_file, force_vector_file = find_msh_files(selected_file)
        
        if not all([mesh_file, stress_tensor_file, force_vector_file]):
            print(f"‚ùå Cannot find required MSH files for {os.path.basename(selected_file)}")
            return False
        
        folder_path = os.path.dirname(mesh_file)
        print(f"\nüîÑ Processing MSH files in {os.path.basename(folder_path)}:")
        print(f"   üìÑ mesh.msh: {os.path.exists(mesh_file)}")
        print(f"   üìÑ smooth_stress_tensor.msh: {os.path.exists(stress_tensor_file)}")
        print(f"   üìÑ force_vector.msh: {os.path.exists(force_vector_file)}")

        print("üîç DEBUG: Starting gmsh initialization...")
        
        # Initialize gmsh with minimal options to avoid signal handling issues
        gmsh.initialize()
        
        # Set options to disable interactive features
        gmsh.option.setNumber("General.Terminal", 0)
        gmsh.option.setNumber("General.Verbosity", 1)
        gmsh.option.setNumber("General.AbortOnError", 0)
        
        print("üîç DEBUG: gmsh initialized successfully")
        gmsh.model.add("FossilsOutput")
        print("üîç DEBUG: gmsh model added successfully")
        
        # Load MSH files
        print("üîç DEBUG: Loading mesh files...")
        gmsh.merge(mesh_file)
        print("üîç DEBUG: mesh.msh loaded")
        gmsh.merge(stress_tensor_file)
        print("üîç DEBUG: stress_tensor.msh loaded")
        gmsh.merge(force_vector_file)
        print("üîç DEBUG: force_vector.msh loaded")

        # Get node data
        nodeTags, nodeCoords, _ = gmsh.model.mesh.getNodes()
        nodeCoords = np.array(nodeCoords).reshape((-1, 3))
        nodeData = pd.DataFrame({
            'NodeTag': nodeTags, 
            'X': nodeCoords[:, 0], 
            'Y': nodeCoords[:, 1], 
            'Z': nodeCoords[:, 2]
        })

        # Process stress tensor data
        dataType, tags, data, time, numComp = gmsh.view.getModelData(1, 0)
        svms = []
        for sig in data:
            [xx, xy, xz, yx, yy, yz, zx, zy, zz] = sig
            svm = np.sqrt(((xx - yy) ** 2 + (yy - zz) ** 2 + (zz - xx) ** 2) / 2 + 3 * (xy * xy + yz * yz + zx * zx))
            svms.append(svm)
        svms = np.array(svms)
        svmData = pd.DataFrame({'Von mises Stress': svms}, index=nodeTags)

        # Combine node and stress data
        nodeData.reset_index(drop=True, inplace=True)
        svmData.reset_index(drop=True, inplace=True)
        combinedData = pd.concat([nodeData, svmData], axis=1)

        # Process force vector data
        dataType_force, tags_force, data_force, time_force, numComp_force = gmsh.view.getModelData(2, 0)
        forces = []
        for force in data_force:
            [fx, fy, fz] = force
            forces.append([fx, fy, fz])
        forces = np.array(forces)
        combinedData = pd.concat([combinedData, pd.DataFrame(forces, columns=['Fx', 'Fy', 'Fz'])], axis=1)

        output_folder = folder_path

        # Export smooth stress tensor to CSV
        if export_smooth_stress:
            csv_file = os.path.join(output_folder, 'smooth_stress_tensor.csv')
            combinedData.to_csv(csv_file, index=False)
            print(f"‚úÖ Smooth stress tensor exported: {os.path.basename(csv_file)}")

        # Export to VTK
        if export_vtk:
            print("üîç DEBUG: Starting VTK export...")
            points = nodeCoords.reshape(-1, 3)
            elementTypes, elementTags, nodeTagsPerElement = gmsh.model.mesh.getElements()
            print("üîç DEBUG: Got mesh elements from gmsh")
            cells = []
            for elementType, nodeTags in zip(elementTypes, nodeTagsPerElement):
                numNodesPerElement = gmsh.model.mesh.getElementProperties(elementType)[3]
                for element in nodeTags.reshape(-1, numNodesPerElement):
                    cells.append(np.insert(element - 1, 0, numNodesPerElement))
            cellsArray = np.concatenate(cells).astype(np.int_)
            print("üîç DEBUG: Creating PyVista mesh...")
            mesh = pv.PolyData(points, cellsArray)
            print("üîç DEBUG: PyVista mesh created successfully")
            mesh.point_data['Von mises Stress'] = svms
            mesh.point_data['Forces'] = forces
            vtk_file_path = os.path.join(output_folder, 'combined_data.vtk')
            print("üîç DEBUG: Saving VTK file...")
            mesh.save(vtk_file_path)
            print(f"‚úÖ VTK file exported: {os.path.basename(vtk_file_path)}")

        print("üîç DEBUG: Finalizing gmsh...")
        gmsh.finalize()
        print("üîç DEBUG: gmsh finalized successfully")

        # Export Von Mises stress summary
        if export_von_mises:
            export_von_mises_summary(selected_file, combinedData, output_folder)

        print(f"‚úÖ MSH processing completed successfully for: {os.path.basename(selected_file)}")
        return True

    except Exception as e:
        print(f"‚ùå Error processing MSH files for {os.path.basename(selected_file)}: {e}")
        try:
            gmsh.finalize()
        except:
            pass
        return False

def export_von_mises_summary(selected_file, combinedData, output_folder):
    """Export Von Mises stress summary to CSV"""
    try:
        # Calculate summary statistics
        von_mises_stats = {
            'File': [os.path.basename(selected_file)],
            'Min Von Mises Stress': [combinedData['Von mises Stress'].min()],
            'Max Von Mises Stress': [combinedData['Von mises Stress'].max()],
            'Mean Von Mises Stress': [combinedData['Von mises Stress'].mean()],
            'Std Von Mises Stress': [combinedData['Von mises Stress'].std()],
            'Total Nodes': [len(combinedData)]
        }
        
        summary_df = pd.DataFrame(von_mises_stats)
        summary_file = os.path.join(output_folder, 'von_mises_summary.csv')
        summary_df.to_csv(summary_file, index=False)
        print(f"‚úÖ Von Mises summary exported: {os.path.basename(summary_file)}")
        
    except Exception as e:
        print(f"‚ùå Error exporting Von Mises summary: {e}")

def main():
    parser = argparse.ArgumentParser(description='Process Fossils MSH output files')
    parser.add_argument('python_file', help='Python file that generated the MSH output')
    parser.add_argument('--export-von-mises', action='store_true', default=True, help='Export Von Mises stress summary')
    parser.add_argument('--export-smooth-stress', action='store_true', default=True, help='Export smooth stress tensor')
    parser.add_argument('--export-vtk', action='store_true', default=True, help='Export VTK file')
    parser.add_argument('--no-von-mises', action='store_true', help='Do not export Von Mises stress summary')
    parser.add_argument('--no-smooth-stress', action='store_true', help='Do not export smooth stress tensor')
    parser.add_argument('--no-vtk', action='store_true', help='Do not export VTK file')
    
    args = parser.parse_args()
    
    # Handle negative flags
    export_von_mises = args.export_von_mises and not args.no_von_mises
    export_smooth_stress = args.export_smooth_stress and not args.no_smooth_stress
    export_vtk = args.export_vtk and not args.no_vtk
    
    print(f"üîÑ Starting MSH processing for: {os.path.basename(args.python_file)}")
    print(f"   Export Von Mises: {export_von_mises}")
    print(f"   Export Smooth Stress: {export_smooth_stress}")
    print(f"   Export VTK: {export_vtk}")
    
    success = process_msh_files(
        args.python_file,
        export_von_mises=export_von_mises,
        export_smooth_stress=export_smooth_stress,
        export_vtk=export_vtk
    )
    
    if success:
        print(f"‚úÖ MSH processing completed successfully")
        sys.exit(0)
    else:
        print(f"‚ùå MSH processing failed")
        sys.exit(1)

if __name__ == "__main__":
    main()
